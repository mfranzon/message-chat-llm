# This guide for setup ollama server and ollama models

## olama setup
Check `ollama` is available:
```bash
ollama
```
If you got a commands - success ðŸŽ‰

### Launch ollama server
```bash
ollama serve
```

### Install LLM model
You can install any models. 
List of them from official repo: https://github.com/ollama/ollama?tab=readme-ov-file#model-library
But the lightweight model is `Llama 3.2`, so we will install it:
```bash
ollama pull llama3.2:1b
```
> [!NOTE]
> This command will download the model for local. Its weight is ~1.3 GB.

### Check models
After downloaded check the avaliable models:
```bash
ollama list
```
My output:
```
ollama list
NAME           ID              SIZE      MODIFIED       
llama3.2:1b    baf6a787fdff    1.3 GB    14 minutes ago 
```
