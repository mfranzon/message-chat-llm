# Guide for launch a LLM server and a server/client program.

## Server side
If you are a server:
1. Lauch `ollama`:
```bash
ollama serve
```
2. Launch server
```bash
python3 server.py
```

## Client side
If you are a client, just run the `client.py`
program and following commands!

Connect as client:
```bash
python3 client.py
```
